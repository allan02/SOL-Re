import streamlit as st
import hashlib
import json
import time
import urllib.request
import urllib.parse
from datetime import datetime, timedelta

from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langchain.callbacks.base import BaseCallbackHandler
from langchain.schema import ChatMessage

from dotenv import load_dotenv

load_dotenv()

# ë‚´ì¥ ë¼ì´ë¸ŒëŸ¬ë¦¬ë§Œ ì‚¬ìš©í•œ ì›¹ API í´ë˜ìŠ¤
class BuiltinWebAPI:
    def __init__(self):
        self.user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    
    def make_request(self, url, headers=None, params=None):
        """urllibì„ ì‚¬ìš©í•œ HTTP ìš”ì²­"""
        try:
            # URLì— íŒŒë¼ë¯¸í„° ì¶”ê°€
            if params:
                url += '?' + urllib.parse.urlencode(params)
            
            # ìš”ì²­ ê°ì²´ ìƒì„±
            req = urllib.request.Request(url)
            req.add_header('User-Agent', self.user_agent)
            
            # ì¶”ê°€ í—¤ë” ì„¤ì •
            if headers:
                for key, value in headers.items():
                    req.add_header(key, value)
            
            # ìš”ì²­ ì‹¤í–‰
            with urllib.request.urlopen(req, timeout=10) as response:
                return json.loads(response.read().decode('utf-8'))
                
        except Exception as e:
            return {'error': str(e)}
    
    def get_weather_info(self, city="ì„œìš¸"):
        """ë‚ ì”¨ ì •ë³´ ì¡°íšŒ (ê³µê°œ API)"""
        try:
            # OpenWeatherMap API (ë¬´ë£Œ)
            api_key = "your_api_key"  # ì‹¤ì œ ì‚¬ìš©ì‹œ API í‚¤ í•„ìš”
            url = f"http://api.openweathermap.org/data/2.5/weather"
            params = {
                'q': city,
                'appid': api_key,
                'units': 'metric',
                'lang': 'kr'
            }
            
            # API í‚¤ê°€ ì—†ìœ¼ë©´ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë°˜í™˜
            if api_key == "your_api_key":
                return {
                    'success': True,
                    'city': city,
                    'temperature': '22Â°C',
                    'description': 'ë§‘ìŒ',
                    'humidity': '65%',
                    'source': 'ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°'
                }
            
            return self.make_request(url, params=params)
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def get_exchange_rate(self):
        """í™˜ìœ¨ ì •ë³´ ì¡°íšŒ (ê³µê°œ API)"""
        try:
            # ë¬´ë£Œ í™˜ìœ¨ API
            url = "https://api.exchangerate-api.com/v4/latest/KRW"
            data = self.make_request(url)
            
            if 'error' not in data:
                return {
                    'success': True,
                    'rates': data.get('rates', {}),
                    'base': data.get('base', 'KRW'),
                    'date': data.get('date', ''),
                    'source': 'ì‹¤ì‹œê°„ API'
                }
            else:
                # API ì˜¤ë¥˜ì‹œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
                return {
                    'success': True,
                    'rates': {'USD': 0.00075, 'EUR': 0.00069, 'JPY': 0.11},
                    'base': 'KRW',
                    'date': datetime.now().strftime('%Y-%m-%d'),
                    'source': 'ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°'
                }
                
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def get_news_info(self, keyword="ë¶€ë™ì‚°"):
        """ë‰´ìŠ¤ ì •ë³´ ì¡°íšŒ (ì‹œë®¬ë ˆì´ì…˜)"""
        try:
            # ì‹¤ì œë¡œëŠ” ë‰´ìŠ¤ API ì‚¬ìš© ê°€ëŠ¥
            news_data = {
                "ë¶€ë™ì‚°": [
                    {"title": "ì„œìš¸ ì•„íŒŒíŠ¸ ê°€ê²© ìƒìŠ¹ì„¸", "summary": "ì„œìš¸ ì•„íŒŒíŠ¸ ê°€ê²©ì´ ì „ì›” ëŒ€ë¹„ 0.5% ìƒìŠ¹"},
                    {"title": "ë¶€ë™ì‚° ì •ì±… ë³€í™”", "summary": "ì •ë¶€, ë¶€ë™ì‚° ê·œì œ ì™„í™” ê²€í† "}
                ],
                "ê²½ì œ": [
                    {"title": "ê¸ˆë¦¬ ì¸í•˜ ê¸°ëŒ€ê°", "summary": "í•œêµ­ì€í–‰ ê¸ˆë¦¬ ì¸í•˜ ê°€ëŠ¥ì„± ë†’ì•„ì§"},
                    {"title": "ì£¼ì‹ì‹œì¥ ìƒìŠ¹", "summary": "ì½”ìŠ¤í”¼ ì§€ìˆ˜ ìƒìŠ¹ì„¸ ì§€ì†"}
                ]
            }
            
            return {
                'success': True,
                'keyword': keyword,
                'news': news_data.get(keyword, news_data["ë¶€ë™ì‚°"]),
                'source': 'ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°'
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def get_market_data(self, region="ì„œìš¸"):
        """ë¶€ë™ì‚° ì‹œì¥ ë°ì´í„° (ì‹œë®¬ë ˆì´ì…˜)"""
        try:
            market_data = {
                "ì„œìš¸": {
                    "avg_price": "1,200ë§Œì›/ã¡",
                    "trend": "ìƒìŠ¹",
                    "volume": "ì¦ê°€",
                    "interest_rate": "3.5%"
                },
                "ë¶€ì‚°": {
                    "avg_price": "800ë§Œì›/ã¡",
                    "trend": "ì•ˆì •",
                    "volume": "ìœ ì§€",
                    "interest_rate": "3.2%"
                },
                "ëŒ€êµ¬": {
                    "avg_price": "700ë§Œì›/ã¡",
                    "trend": "í•˜ë½",
                    "volume": "ê°ì†Œ",
                    "interest_rate": "3.3%"
                }
            }
            
            return {
                'success': True,
                'region': region,
                'data': market_data.get(region, market_data["ì„œìš¸"]),
                'last_updated': datetime.now().strftime('%Y-%m-%d'),
                'source': 'ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°'
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}

# ì „ì—­ API ì¸ìŠ¤í„´ìŠ¤
if 'builtin_api' not in st.session_state:
    st.session_state.builtin_api = BuiltinWebAPI()

# Q&A ì „ìš© ìºì‹œ ì‹œìŠ¤í…œ
class QACache:
    def __init__(self):
        self.qa_cache = {}  # Q&A ìŒ ì €ì¥
        self.stats = {
            'hits': 0,      # ìºì‹œ íˆíŠ¸ íšŸìˆ˜
            'misses': 0,    # ìºì‹œ ë¯¸ìŠ¤ íšŸìˆ˜
            'saves': 0      # ìºì‹œ ì €ì¥ íšŸìˆ˜
        }
    
    def get(self, question, context_id=None):
        """ì§ˆë¬¸ê³¼ ì»¨í…ìŠ¤íŠ¸ IDë¡œ ë‹µë³€ ì¡°íšŒ"""
        cache_key = self._generate_key(question, context_id)
        
        if cache_key in self.qa_cache:
            data, expire_time = self.qa_cache[cache_key]
            if datetime.now() < expire_time:
                self.stats['hits'] += 1
                return data
            else:
                del self.qa_cache[cache_key]
        
        self.stats['misses'] += 1
        return None
    
    def set(self, question, answer, context_id=None, expire_seconds=3600):
        """ì§ˆë¬¸-ë‹µë³€ ìŒì„ ìºì‹œì— ì €ì¥"""
        cache_key = self._generate_key(question, context_id)
        expire_time = datetime.now() + timedelta(seconds=expire_seconds)
        
        cache_data = {
            'question': question,
            'answer': answer,
            'context_id': context_id,
            'timestamp': str(datetime.now()),
            'expire_time': str(expire_time)
        }
        
        self.qa_cache[cache_key] = (cache_data, expire_time)
        self.stats['saves'] += 1
    
    def _generate_key(self, question, context_id=None):
        """ì§ˆë¬¸ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìºì‹œ í‚¤ ìƒì„±"""
        key_data = {
            'question': question.lower().strip(),
            'context_id': context_id or 'default'
        }
        return hashlib.md5(json.dumps(key_data, sort_keys=True).encode()).hexdigest()
    
    def clear_expired(self):
        """ë§Œë£Œëœ ìºì‹œ ì •ë¦¬"""
        current_time = datetime.now()
        expired_keys = [key for key, (_, expire_time) in self.qa_cache.items() 
                       if current_time >= expire_time]
        for key in expired_keys:
            del self.qa_cache[key]
    
    def get_stats(self):
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        total_requests = self.stats['hits'] + self.stats['misses']
        hit_rate = (self.stats['hits'] / total_requests * 100) if total_requests > 0 else 0
        
        return {
            'hits': self.stats['hits'],
            'misses': self.stats['misses'],
            'saves': self.stats['saves'],
            'hit_rate': round(hit_rate, 2),
            'cache_size': len(self.qa_cache)
        }
    
    def clear_all(self):
        """ëª¨ë“  ìºì‹œ ì‚­ì œ"""
        self.qa_cache.clear()
        self.stats = {'hits': 0, 'misses': 0, 'saves': 0}

# ì „ì—­ Q&A ìºì‹œ ì¸ìŠ¤í„´ìŠ¤
if 'qa_cache' not in st.session_state:
    st.session_state.qa_cache = QACache()

# ë©”ëª¨ë¦¬ ê¸°ë°˜ ìºì‹œ (Redis ëŒ€ì‹ )
class MemoryCache:
    def __init__(self):
        self.cache = {}
    
    def get(self, key):
        if key in self.cache:
            data, expire_time = self.cache[key]
            if datetime.now() < expire_time:
                return data
            else:
                del self.cache[key]
        return None
    
    def set(self, key, value, expire_seconds=3600):
        expire_time = datetime.now() + timedelta(seconds=expire_seconds)
        self.cache[key] = (value, expire_time)
    
    def clear_expired(self):
        current_time = datetime.now()
        expired_keys = [key for key, (_, expire_time) in self.cache.items() 
                       if current_time >= expire_time]
        for key in expired_keys:
            del self.cache[key]

# ì „ì—­ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤
if 'memory_cache' not in st.session_state:
    st.session_state.memory_cache = MemoryCache()

# Query Rewriting í´ë˜ìŠ¤
class QueryRewriter:
    def __init__(self):
        self.rewriting_patterns = {
            # ì¼ë°˜ì ì¸ ì§ˆë¬¸ íŒ¨í„´
            "ê´œì°®ì•„": "ì´ ê³„ì•½ì˜ ì£¼ìš” ì¡°ê±´ê³¼ ìœ„í—˜ ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "ì–´ë•Œ": "ì´ ê³„ì•½ì˜ ì¥ë‹¨ì ê³¼ ì£¼ì˜ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì¢‹ì•„": "ì´ ê³„ì•½ì˜ ìœ ë¦¬í•œ ì ê³¼ ë¶ˆë¦¬í•œ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            
            # ê°€ê²© ê´€ë ¨
            "ë¹„ì‹¸": "ì´ ê³„ì•½ì˜ ê°€ê²©ì´ ì‹œì¥ ê°€ê²© ëŒ€ë¹„ ì ì •í•œê°€ìš”?",
            "ì‹¸": "ì´ ê³„ì•½ì˜ ê°€ê²©ì´ ì‹œì¥ ê°€ê²© ëŒ€ë¹„ ì €ë ´í•œê°€ìš”?",
            "ê°€ê²©": "ì´ ê³„ì•½ì˜ ê°€ê²© ì¡°ê±´ê³¼ ì‹œì¥ ë¹„êµëŠ” ì–´ë– í•œê°€ìš”?",
            
            # ì¡°ê±´ ê´€ë ¨
            "ì¡°ê±´": "ì´ ê³„ì•½ì˜ ì£¼ìš” ì¡°ê±´ë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”",
            "ê¸°ê°„": "ì´ ê³„ì•½ì˜ ê¸°ê°„ ì¡°ê±´ì´ ì ì ˆí•œê°€ìš”?",
            "ë³´ì¦ê¸ˆ": "ë³´ì¦ê¸ˆ ì¡°ê±´ì´ í•©ë¦¬ì ì¸ê°€ìš”?",
            
            # ìœ„í—˜ ê´€ë ¨
            "ìœ„í—˜": "ì´ ê³„ì•½ì˜ ì£¼ìš” ìœ„í—˜ ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "ì£¼ì˜": "ì´ ê³„ì•½ì—ì„œ ì£¼ì˜í•´ì•¼ í•  ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ë¬¸ì œ": "ì´ ê³„ì•½ì˜ ì ì¬ì  ë¬¸ì œì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
        }
        
        # ë¶€ë™ì‚° ì „ë¬¸ ìš©ì–´ ë§¤í•‘
        self.real_estate_terms = {
            "ì›”ì„¸": "ì›”ì„¸ ì¡°ê±´",
            "ì „ì„¸": "ì „ì„¸ ì¡°ê±´", 
            "ë§¤ë§¤": "ë§¤ë§¤ ì¡°ê±´",
            "ì„ëŒ€": "ì„ëŒ€ ì¡°ê±´",
            "ë“±ê¸°": "ë“±ê¸°ë¶€ë“±ë³¸",
            "íŠ¹ì•½": "íŠ¹ì•½ì‚¬í•­",
            "ì¤‘ê°œ": "ì¤‘ê°œìˆ˜ìˆ˜ë£Œ",
            "ë“±ë¡": "ë“±ë¡ì„¸",
            "ì·¨ë“": "ì·¨ë“ì„¸"
        }
    
    def rewrite_query(self, original_query: str) -> dict:
        """ì§ˆë¬¸ì„ ì¬êµ¬ì„±í•˜ì—¬ ë” ì •í™•í•œ ê²€ìƒ‰ì„ ìœ„í•œ ì¿¼ë¦¬ ìƒì„±"""
        try:
            # 1. ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            query_info = {
                'original': original_query,
                'rewritten': original_query,
                'keywords': [],
                'intent': 'general',
                'confidence': 1.0
            }
            
            # 2. í‚¤ì›Œë“œ ì¶”ì¶œ
            query_info['keywords'] = self._extract_keywords(original_query)
            
            # 3. ì˜ë„ íŒŒì•…
            query_info['intent'] = self._detect_intent(original_query)
            
            # 4. ì§ˆë¬¸ ì¬êµ¬ì„±
            rewritten = self._rewrite_question(original_query)
            query_info['rewritten'] = rewritten
            
            # 5. ì‹ ë¢°ë„ ê³„ì‚°
            query_info['confidence'] = self._calculate_confidence(original_query, rewritten)
            
            return query_info
            
        except Exception as e:
            return {
                'original': original_query,
                'rewritten': original_query,
                'keywords': [],
                'intent': 'general',
                'confidence': 0.5,
                'error': str(e)
            }
    
    def _extract_keywords(self, query: str) -> list:
        """ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        
        # ë¶€ë™ì‚° ì „ë¬¸ ìš©ì–´ ê²€ìƒ‰
        for term, meaning in self.real_estate_terms.items():
            if term in query:
                keywords.append(meaning)
        
        # ì¼ë°˜ì ì¸ í‚¤ì›Œë“œ ê²€ìƒ‰
        common_keywords = ["ê³„ì•½", "ë¶€ë™ì‚°", "ì„ëŒ€", "ë§¤ë§¤", "ê°€ê²©", "ì¡°ê±´", "ê¸°ê°„", "ë³´ì¦ê¸ˆ", "ì›”ì„¸", "ì „ì„¸"]
        for keyword in common_keywords:
            if keyword in query:
                keywords.append(keyword)
        
        return list(set(keywords))  # ì¤‘ë³µ ì œê±°
    
    def _detect_intent(self, query: str) -> str:
        """ì§ˆë¬¸ì˜ ì˜ë„ íŒŒì•…"""
        query_lower = query.lower()
        
        if any(word in query_lower for word in ["ê°€ê²©", "ë¹„ì‹¸", "ì‹¸", "ì–¼ë§ˆ"]):
            return "price_analysis"
        elif any(word in query_lower for word in ["ìœ„í—˜", "ì£¼ì˜", "ë¬¸ì œ", "ê´œì°®ì•„"]):
            return "risk_analysis"
        elif any(word in query_lower for word in ["ì¡°ê±´", "ê¸°ê°„", "ë³´ì¦ê¸ˆ"]):
            return "condition_analysis"
        elif any(word in query_lower for word in ["ë¹„êµ", "ë‹¤ë¥¸", "ì‹œì¥"]):
            return "comparison"
        elif any(word in query_lower for word in ["ìš”ì•½", "ì •ë¦¬", "í•µì‹¬"]):
            return "summary"
        else:
            return "general"
    
    def _rewrite_question(self, query: str) -> str:
        """ì§ˆë¬¸ ì¬êµ¬ì„±"""
        query_lower = query.lower()
        
        # íŒ¨í„´ ë§¤ì¹­ì„ í†µí•œ ì¬êµ¬ì„±
        for pattern, replacement in self.rewriting_patterns.items():
            if pattern in query_lower:
                return replacement
        
        # ì˜ë„ë³„ ê¸°ë³¸ ì¬êµ¬ì„±
        intent = self._detect_intent(query)
        if intent == "price_analysis":
            return f"ì´ ê³„ì•½ì˜ ê°€ê²© ì¡°ê±´ê³¼ ì‹œì¥ ë¹„êµ ë¶„ì„: {query}"
        elif intent == "risk_analysis":
            return f"ì´ ê³„ì•½ì˜ ìœ„í—˜ ìš”ì†Œì™€ ì£¼ì˜ì‚¬í•­ ë¶„ì„: {query}"
        elif intent == "condition_analysis":
            return f"ì´ ê³„ì•½ì˜ ì£¼ìš” ì¡°ê±´ ë¶„ì„: {query}"
        elif intent == "comparison":
            return f"ì´ ê³„ì•½ì˜ ì‹œì¥ ë¹„êµ ë¶„ì„: {query}"
        elif intent == "summary":
            return f"ì´ ê³„ì•½ì˜ í•µì‹¬ ìš”ì•½: {query}"
        else:
            return f"ì´ ê³„ì•½ì— ëŒ€í•œ ì¢…í•© ë¶„ì„: {query}"
    
    def _calculate_confidence(self, original: str, rewritten: str) -> float:
        """ì¬êµ¬ì„± ì‹ ë¢°ë„ ê³„ì‚°"""
        # ê°„ë‹¨í•œ ì‹ ë¢°ë„ ê³„ì‚° (0.0 ~ 1.0)
        if original == rewritten:
            return 0.5  # ë³€ê²½ ì—†ìŒ
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì‹ ë¢°ë„
        keywords = self._extract_keywords(original)
        if len(keywords) > 0:
            return min(0.9, 0.5 + len(keywords) * 0.1)
        
        return 0.7  # ê¸°ë³¸ ì‹ ë¢°ë„

# ì „ì—­ Query Rewriter ì¸ìŠ¤í„´ìŠ¤
if 'query_rewriter' not in st.session_state:
    st.session_state.query_rewriter = QueryRewriter()

# ê°„ë‹¨í•œ Re-ranking í´ë˜ìŠ¤
class SimpleReranker:
    def __init__(self):
        # í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì„¤ì •
        self.keyword_weights = {
            'ê³„ì•½': 2.0,
            'ì„ëŒ€': 1.8,
            'ë§¤ë§¤': 1.8,
            'ë³´ì¦ê¸ˆ': 1.5,
            'ì›”ì„¸': 1.5,
            'ì „ì„¸': 1.5,
            'ê¸°ê°„': 1.3,
            'ê°€ê²©': 1.3,
            'ì¡°ê±´': 1.2,
            'íŠ¹ì•½': 1.2,
            'ë“±ê¸°': 1.1,
            'ì¤‘ê°œ': 1.1
        }
        
        # ìœ„ì¹˜ ê°€ì¤‘ì¹˜ (ë¬¸ì„œ ë‚´ ìœ„ì¹˜ì— ë”°ë¥¸ ì¤‘ìš”ë„)
        self.position_weights = {
            'title': 3.0,      # ì œëª© ì˜ì—­
            'header': 2.0,     # í—¤ë” ì˜ì—­
            'body': 1.0,       # ë³¸ë¬¸ ì˜ì—­
            'footer': 0.5      # í‘¸í„° ì˜ì—­
        }
    
    def rerank_documents(self, query: str, documents: list, top_k: int = 3) -> list:
        """ë¬¸ì„œë“¤ì„ ì¬ì •ë ¬í•˜ì—¬ ìƒìœ„ kê°œ ë°˜í™˜"""
        try:
            if not documents:
                return []
            
            # ê° ë¬¸ì„œì— ì ìˆ˜ ê³„ì‚°
            scored_docs = []
            for i, doc in enumerate(documents):
                score = self._calculate_document_score(query, doc, i)
                scored_docs.append((doc, score))
            
            # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            scored_docs.sort(key=lambda x: x[1], reverse=True)
            
            # ìƒìœ„ kê°œ ë¬¸ì„œ ë°˜í™˜
            reranked_docs = [doc for doc, score in scored_docs[:top_k]]
            
            # ë””ë²„ê¹… ì •ë³´ (ê°œë°œ ëª¨ë“œì—ì„œë§Œ)
            if st.session_state.get('debug_mode', False):
                st.sidebar.info(f"ğŸ” Re-ranking ê²°ê³¼:")
                for i, (doc, score) in enumerate(scored_docs[:3]):
                    st.sidebar.write(f"{i+1}. ì ìˆ˜: {score:.2f}")
            
            return reranked_docs
            
        except Exception as e:
            st.error(f"Re-ranking ì˜¤ë¥˜: {str(e)}")
            return documents[:top_k]  # ì˜¤ë¥˜ì‹œ ì›ë³¸ ìˆœì„œ ë°˜í™˜
    
    def _calculate_document_score(self, query: str, document, original_rank: int) -> float:
        """ë¬¸ì„œì˜ ì ìˆ˜ë¥¼ ê³„ì‚°"""
        try:
            content = document.page_content.lower()
            query_lower = query.lower()
            
            # 1. í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ (40%)
            keyword_score = self._calculate_keyword_score(query_lower, content)
            
            # 2. í…ìŠ¤íŠ¸ ê¸¸ì´ ì ìˆ˜ (20%)
            length_score = self._calculate_length_score(content)
            
            # 3. ìœ„ì¹˜ ì ìˆ˜ (20%)
            position_score = self._calculate_position_score(content)
            
            # 4. ì›ë³¸ ìˆœìœ„ ì ìˆ˜ (20%)
            rank_score = self._calculate_rank_score(original_rank)
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            final_score = (
                keyword_score * 0.4 +
                length_score * 0.2 +
                position_score * 0.2 +
                rank_score * 0.2
            )
            
            return final_score
            
        except Exception as e:
            return 0.0
    
    def _calculate_keyword_score(self, query: str, content: str) -> float:
        """í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        # ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        query_words = query.split()
        
        for word in query_words:
            if word in content:
                # í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì ìš©
                weight = self.keyword_weights.get(word, 1.0)
                score += weight
        
        # ì •ê·œí™” (0~1 ë²”ìœ„)
        return min(score / 10.0, 1.0)
    
    def _calculate_length_score(self, content: str) -> float:
        """í…ìŠ¤íŠ¸ ê¸¸ì´ ì ìˆ˜ ê³„ì‚° (ì ë‹¹í•œ ê¸¸ì´ê°€ ë†’ì€ ì ìˆ˜)"""
        length = len(content)
        
        # 100~500ì ì •ë„ê°€ ì ë‹¹
        if 100 <= length <= 500:
            return 1.0
        elif 50 <= length <= 1000:
            return 0.8
        else:
            return 0.5
    
    def _calculate_position_score(self, content: str) -> float:
        """ìœ„ì¹˜ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°"""
        # ê°„ë‹¨í•œ ìœ„ì¹˜ ì¶”ì • (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë¶„ì„ í•„ìš”)
        lines = content.split('\n')
        
        if len(lines) <= 3:  # ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ì œëª©ìœ¼ë¡œ ê°„ì£¼
            return self.position_weights['title']
        elif len(lines) <= 10:  # ì¤‘ê°„ ê¸¸ì´ëŠ” í—¤ë”ë¡œ ê°„ì£¼
            return self.position_weights['header']
        else:  # ê¸´ í…ìŠ¤íŠ¸ëŠ” ë³¸ë¬¸ìœ¼ë¡œ ê°„ì£¼
            return self.position_weights['body']
    
    def _calculate_rank_score(self, original_rank: int) -> float:
        """ì›ë³¸ ìˆœìœ„ ì ìˆ˜ ê³„ì‚° (ë†’ì€ ìˆœìœ„ê°€ ë†’ì€ ì ìˆ˜)"""
        # ì—­ìˆœìœ¼ë¡œ ì ìˆ˜ ê³„ì‚° (1ìœ„ê°€ 1.0, 2ìœ„ê°€ 0.9, ...)
        return max(0.1, 1.0 - (original_rank * 0.1))

# ì „ì—­ Re-ranker ì¸ìŠ¤í„´ìŠ¤
if 'reranker' not in st.session_state:
    st.session_state.reranker = SimpleReranker()

# í•„ìˆ˜ session_state ì´ˆê¸°í™”
if 'vectorstore' not in st.session_state:
    st.session_state.vectorstore = None
if 'raw_text' not in st.session_state:
    st.session_state.raw_text = None
if 'file_name' not in st.session_state:
    st.session_state.file_name = None
if 'upload_time' not in st.session_state:
    st.session_state.upload_time = None

# ìºì‹œ í‚¤ ìƒì„± í•¨ìˆ˜
def generate_cache_key(query, vectorstore_id=None):
    """ì¿¼ë¦¬ì™€ ë²¡í„°ìŠ¤í† ì–´ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìºì‹œ í‚¤ ìƒì„±"""
    key_data = {
        'query': query,
        'vectorstore_id': vectorstore_id
    }
    return hashlib.md5(json.dumps(key_data, sort_keys=True).encode()).hexdigest()

# ìºì‹œì—ì„œ ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°
def get_cached_response(cache_key):
    """ìºì‹œì—ì„œ ì‘ë‹µì„ ê°€ì ¸ì˜´"""
    # ë§Œë£Œëœ ìºì‹œ ì •ë¦¬
    st.session_state.memory_cache.clear_expired()
    
    cached_data = st.session_state.memory_cache.get(cache_key)
    if cached_data:
        return cached_data
    return None

# ì‘ë‹µì„ ìºì‹œì— ì €ì¥
def cache_response(cache_key, response, expire_time=3600):
    """ì‘ë‹µì„ ìºì‹œì— ì €ì¥ (ê¸°ë³¸ 1ì‹œê°„)"""
    cache_data = {
        'response': response,
        'timestamp': str(datetime.now())
    }
    st.session_state.memory_cache.set(cache_key, cache_data, expire_time)


# handle streaming conversation
class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text)

# Function to extract text from an PDF file
from pdfminer.high_level import extract_text

def get_pdf_text(filename):
    raw_text = extract_text(filename)
    return raw_text

# document preprocess
def process_uploaded_file(uploaded_file):
    # Load document if file is uploaded
    if uploaded_file is not None:
        # loader
        raw_text = get_pdf_text(uploaded_file)
        # splitter
        text_splitter = CharacterTextSplitter(
        separator = "\n\n",
        chunk_size = 1000,
        chunk_overlap  = 200,
        )
        all_splits = text_splitter.create_documents([raw_text])
        print("ì´ " + str(len(all_splits)) + "ê°œì˜ passage")        
        # storage
        vectorstore = FAISS.from_documents(all_splits, OpenAIEmbeddings())
        return vectorstore, raw_text
    return None

# generate response using RAG technic with caching
def generate_response(query_text, vectorstore, callback):

    # Query Rewriting ì ìš©
    query_info = st.session_state.query_rewriter.rewrite_query(query_text)
    rewritten_query = query_info['rewritten']
    
    # Query Rewriting ì •ë³´ í‘œì‹œ (ì‹ ë¢°ë„ê°€ ë†’ì„ ë•Œë§Œ)
    if query_info['confidence'] > 0.7 and query_info['original'] != query_info['rewritten']:
        st.info(f"ğŸ” ì§ˆë¬¸ ì¬êµ¬ì„±: '{query_info['original']}' â†’ '{query_info['rewritten']}' (ì‹ ë¢°ë„: {query_info['confidence']:.1%})")
    
    # ì»¨í…ìŠ¤íŠ¸ ID ìƒì„± (íŒŒì¼ ê¸°ë°˜)
    context_id = f"{st.session_state.get('file_name', 'unknown')}_{st.session_state.get('upload_time', '')}"
    
    # Q&A ìºì‹œì—ì„œ ì‘ë‹µ í™•ì¸ (ì¬êµ¬ì„±ëœ ì¿¼ë¦¬ë¡œ)
    cached_result = st.session_state.qa_cache.get(rewritten_query, context_id)
    if cached_result:
        st.success(f"ğŸ’¾ ìºì‹œëœ ë‹µë³€ì„ ì‚¬ìš©í•©ë‹ˆë‹¤! (íˆíŠ¸ìœ¨: {st.session_state.qa_cache.get_stats()['hit_rate']}%)")
        return cached_result['answer']

    # retriever (ì¬êµ¬ì„±ëœ ì¿¼ë¦¬ ì‚¬ìš©)
    docs_list = vectorstore.similarity_search(rewritten_query, k=5)  # ë” ë§ì€ ë¬¸ì„œ ê²€ìƒ‰
    
    # Re-ranking ì ìš©
    reranked_docs = st.session_state.reranker.rerank_documents(rewritten_query, docs_list, top_k=3)
    
    docs = ""
    for i, doc in enumerate(reranked_docs):
        docs += f"'ë¬¸ì„œ{i+1}':{doc.page_content}\n" 
    
    # ë‚´ì¥ API ì •ë³´ ìˆ˜ì§‘
    api_info = ""
    
    # ì‹œì¥ ë°ì´í„° ì¡°íšŒ
    if any(keyword in query_text for keyword in ["ì‹œì„¸", "ê°€ê²©", "ì‹œì¥", "ê²½ì œ", "ê¸ˆë¦¬"]):
        market_data = st.session_state.builtin_api.get_market_data("ì„œìš¸")
        if market_data['success']:
            api_info += f"\n[ì‹œì¥ ì •ë³´]\n"
            api_info += f"í‰ê·  ê°€ê²©: {market_data['data']['avg_price']}\n"
            api_info += f"ì‹œì¥ ë™í–¥: {market_data['data']['trend']}\n"
            api_info += f"ê±°ë˜ëŸ‰: {market_data['data']['volume']}\n"
            api_info += f"ê¸ˆë¦¬: {market_data['data']['interest_rate']}\n"
    
    # ë‰´ìŠ¤ ì •ë³´ ì¡°íšŒ
    if any(keyword in query_text for keyword in ["ë‰´ìŠ¤", "ì†Œì‹", "ì •ì±…", "ë³€í™”"]):
        news_data = st.session_state.builtin_api.get_news_info("ë¶€ë™ì‚°")
        if news_data['success']:
            api_info += f"\n[ìµœì‹  ë‰´ìŠ¤]\n"
            for i, news in enumerate(news_data['news'][:2], 1):
                api_info += f"{i}. {news['title']}\n"
                api_info += f"   {news['summary']}\n"
    
    # í™˜ìœ¨ ì •ë³´ ì¡°íšŒ
    if any(keyword in query_text for keyword in ["í™˜ìœ¨", "ë‹¬ëŸ¬", "ì™¸í™”", "í•´ì™¸"]):
        exchange_data = st.session_state.builtin_api.get_exchange_rate()
        if exchange_data['success']:
            api_info += f"\n[í™˜ìœ¨ ì •ë³´]\n"
            rates = exchange_data['rates']
            api_info += f"USD: {rates.get('USD', 0):.4f} KRW\n"
            api_info += f"EUR: {rates.get('EUR', 0):.4f} KRW\n"
            api_info += f"JPY: {rates.get('JPY', 0):.2f} KRW\n"
    
    # ë‚ ì”¨ ì •ë³´ ì¡°íšŒ
    if any(keyword in query_text for keyword in ["ë‚ ì”¨", "ê¸°í›„", "í™˜ê²½"]):
        weather_data = st.session_state.builtin_api.get_weather_info("ì„œìš¸")
        if weather_data['success']:
            api_info += f"\n[ë‚ ì”¨ ì •ë³´]\n"
            api_info += f"ì˜¨ë„: {weather_data['temperature']}\n"
            api_info += f"ë‚ ì”¨: {weather_data['description']}\n"
            api_info += f"ìŠµë„: {weather_data['humidity']}\n"
        
    # generator
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0, streaming=True, callbacks=[callback])
    
    # chaining (ë‚´ì¥ API ì •ë³´ í¬í•¨)
    rag_prompt = [
        SystemMessage(
            content="ë„ˆëŠ” ë¶€ë™ì‚° ê³„ì•½ì„œë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ 'ë¶€ë™ì‚° ê³„ì•½ì„œ ë¶„ì„ ë´‡'ì´ì•¼. ì£¼ì–´ì§„ ê³„ì•½ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ í•´ì¤˜. ì¶”ê°€ë¡œ ì œê³µë˜ëŠ” ì‹¤ì‹œê°„ ì‹œì¥ ì •ë³´, ë‰´ìŠ¤, í™˜ìœ¨, ë‚ ì”¨ ì •ë³´ë„ í•¨ê»˜ í™œìš©í•´ì„œ ë” ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ì¤˜. ê³„ì•½ì„œì— ë‚´ìš©ì´ ì •í™•í•˜ê²Œ ë‚˜ì™€ìˆì§€ ì•Šìœ¼ë©´ 'í•´ë‹¹ ë‚´ìš©ì€ ê³„ì•½ì„œì— ëª…ì‹œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.'ë¼ê³  ëŒ€ë‹µí•´ì¤˜."
        ),
        HumanMessage(
        content=f"ì§ˆë¬¸:{query_text}\n\n[ê³„ì•½ì„œ ë‚´ìš©]\n{docs}\n\n[ì‹¤ì‹œê°„ ì •ë³´]\n{api_info}"
        ),
    ]

    response = llm.invoke(rag_prompt)
    
    # Q&A ìºì‹œì— ì €ì¥
    st.session_state.qa_cache.set(query_text, response.content, context_id)
    st.sidebar.info(f"ğŸ’¾ Q&Aê°€ ìºì‹œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! (ìºì‹œ í¬ê¸°: {st.session_state.qa_cache.get_stats()['cache_size']})")
    
    return response.content


def generate_summarize(raw_text, callback):

    # ìš”ì•½ìš© ì»¨í…ìŠ¤íŠ¸ ID
    text_hash = hashlib.md5(raw_text.encode()).hexdigest()
    context_id = f"summary_{text_hash}"
    
    # Q&A ìºì‹œì—ì„œ ìš”ì•½ í™•ì¸
    cached_result = st.session_state.qa_cache.get("ìš”ì•½", context_id)
    if cached_result:
        st.success(f"ğŸ’¾ ìºì‹œëœ ìš”ì•½ì„ ì‚¬ìš©í•©ë‹ˆë‹¤! (íˆíŠ¸ìœ¨: {st.session_state.qa_cache.get_stats()['hit_rate']}%)")
        return cached_result['answer']

    # generator 
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0, streaming=True, callbacks=[callback])
    
    # prompt formatting
    rag_prompt = [
        SystemMessage(
            content="ë‹¤ìŒ ë‚˜ì˜¬ ë¶€ë™ì‚° ê³„ì•½ì„œë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•´ì„œ ìš”ì•½í•´ì¤˜. ë‹¤ìŒ í•­ëª©ë“¤ì„ í¬í•¨í•´ì„œ ì •ë¦¬í•´ì¤˜:\n\n1. ê³„ì•½ì„œ ê¸°ë³¸ ì •ë³´ (ê³„ì•½ ì¢…ë¥˜, ê³„ì•½ì¼)\n2. ê³„ì•½ ë‹¹ì‚¬ì ì •ë³´\n3. ë¶€ë™ì‚° ì •ë³´ (ì£¼ì†Œ, ë©´ì , ìš©ë„ ë“±)\n4. ê³„ì•½ ì¡°ê±´ (ì„ëŒ€ë£Œ/ë§¤ë§¤ê°€ê²©, ê³„ì•½ê¸°ê°„, ë³´ì¦ê¸ˆ ë“±)\n5. ì£¼ìš” íŠ¹ì•½ì‚¬í•­\n6. ì£¼ì˜ì‚¬í•­ ë° ìœ„í—˜ ìš”ì†Œ\n7. ë²•ì  ê²€í†  ì‚¬í•­\n\nì¤‘ìš”í•œ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•´ì¤˜."
        ),
        HumanMessage(
            content=raw_text
        ),
    ]
    
    response = llm(rag_prompt)
    
    # Q&A ìºì‹œì— ìš”ì•½ ì €ì¥ (ë” ì˜¤ë˜ ë³´ê´€)
    st.session_state.qa_cache.set("ìš”ì•½", response.content, context_id, expire_seconds=7200)
    st.sidebar.info(f"ğŸ’¾ ìš”ì•½ì´ Q&A ìºì‹œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! (ìºì‹œ í¬ê¸°: {st.session_state.qa_cache.get_stats()['cache_size']})")
    
    return response.content


# page title
st.set_page_config(page_title='ğŸ  ë¶€ë™ì‚° ê³„ì•½ì„œ ë¶„ì„ ì±—ë´‡')
st.title('ğŸ  ë¶€ë™ì‚° ê³„ì•½ì„œ ë¶„ì„ ì±—ë´‡')

# ìŠ¤ë§ˆíŠ¸ ê³„ì•½ ë¶„ì„ ì†Œê°œ (ì¤‘ì•™ í™”ë©´)
st.markdown("""
<div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
            border-radius: 15px; 
            padding: 30px; 
            color: white; 
            margin: 20px 0;
            text-align: center;">
    <h2 style="color: white; margin-bottom: 20px;">ğŸ  ìŠ¤ë§ˆíŠ¸ ê³„ì•½ ë¶„ì„</h2>
    <p style="font-size: 16px; line-height: 1.8; margin-bottom: 20px;">
        ê³„ì•½ì„œ ë¶„ì„ê³¼ í•¨ê»˜ <strong>ì‹¤ì‹œê°„ ê²½ì œ ë°ì´í„°</strong>ë¥¼ í™œìš©í•˜ì—¬ 
        ë”ìš± ì •í™•í•œ íŒë‹¨ì„ ë„ì™€ë“œë¦½ë‹ˆë‹¤!
    </p>
    <div style="display: flex; justify-content: space-around; flex-wrap: wrap; gap: 20px;">
        <div style="background: rgba(255,255,255,0.2); padding: 15px; border-radius: 10px; min-width: 200px;">
            <h4 style="color: white; margin-bottom: 10px;">ğŸ“Š ì‹¤ì‹œê°„ ì‹œì¥ ì •ë³´</h4>
            <p style="font-size: 14px;">ë¶€ë™ì‚° ì‹œì„¸, ê¸ˆë¦¬, ê±°ë˜ëŸ‰</p>
        </div>
        <div style="background: rgba(255,255,255,0.2); padding: 15px; border-radius: 10px; min-width: 200px;">
            <h4 style="color: white; margin-bottom: 10px;">ğŸ” ìŠ¤ë§ˆíŠ¸ ì§ˆë¬¸ ì¬êµ¬ì„±</h4>
            <p style="font-size: 14px;">ê°„ë‹¨í•œ ì§ˆë¬¸ë„ ì •í™•í•˜ê²Œ ë³€í™˜</p>
        </div>
        <div style="background: rgba(255,255,255,0.2); padding: 15px; border-radius: 10px; min-width: 200px;">
            <h4 style="color: white; margin-bottom: 10px;">ğŸ’¾ ì§€ëŠ¥í˜• ìºì‹±</h4>
            <p style="font-size: 14px;">ë¹ ë¥¸ ì‘ë‹µê³¼ ì¼ê´€ëœ ë‹µë³€</p>
        </div>
    </div>
</div>
""", unsafe_allow_html=True)

# ì§ˆë¬¸ ì˜ˆì‹œ (ì¤‘ì•™ í™”ë©´)
st.markdown("""
<div style="background: #f8f9fa; border-radius: 15px; padding: 25px; margin: 20px 0;">
    <h3 style="color: #333; margin-bottom: 20px;">ğŸ’¡ ì´ëŸ° ì§ˆë¬¸ë„ ê°€ëŠ¥í•´ìš”</h3>
    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px;">
        <div style="background: white; padding: 20px; border-radius: 10px; border-left: 4px solid #667eea;">
            <h4 style="color: #667eea; margin-bottom: 15px;">ğŸ¯ ê°€ê²© ë¶„ì„</h4>
            <ul style="color: #555; line-height: 1.6;">
                <li>"í˜„ì¬ ê²½ì œ ìƒí™©ì—ì„œ ë‚´ ê³„ì•½ ê¸ˆì•¡ì´ ì ì •í•œê°€ìš”?"</li>
                <li>"ì‹œì¥ ë™í–¥ì„ ê³ ë ¤í–ˆì„ ë•Œ ì´ ê³„ì•½ì´ ìœ ë¦¬í•œê°€ìš”?"</li>
            </ul>
        </div>
        <div style="background: white; padding: 20px; border-radius: 10px; border-left: 4px solid #764ba2;">
            <h4 style="color: #764ba2; margin-bottom: 15px;">ğŸ“Š ì‹œì¥ ë¹„êµ</h4>
            <ul style="color: #555; line-height: 1.6;">
                <li>"ê°™ì€ ì§€ì—­ ë‹¤ë¥¸ ê³„ì•½ê³¼ ë¹„êµí•˜ë©´ ì–´ë–¤ê°€ìš”?"</li>
                <li>"ê¸ˆë¦¬ ë³€ë™ì´ ì´ ê³„ì•½ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?"</li>
            </ul>
        </div>
        <div style="background: white; padding: 20px; border-radius: 10px; border-left: 4px solid #ff9a9e;">
            <h4 style="color: #ff9a9e; margin-bottom: 15px;">ğŸ” ë¦¬ìŠ¤í¬ ë¶„ì„</h4>
            <ul style="color: #555; line-height: 1.6;">
                <li>"í˜„ì¬ ê²½ì œ ìƒí™©ì—ì„œ ì´ ê³„ì•½ì˜ ìœ„í—˜ ìš”ì†ŒëŠ”?"</li>
                <li>"í™˜ìœ¨ ë³€ë™ì´ ê³„ì•½ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?"</li>
            </ul>
        </div>
    </div>
</div>
""", unsafe_allow_html=True)

# ìŠ¤ë§ˆíŠ¸ ì§ˆë¬¸ ì¬êµ¬ì„± ì˜ˆì‹œ (ì¤‘ì•™ í™”ë©´)
st.markdown("""
<div style="background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%); 
            border-radius: 15px; 
            padding: 25px; 
            margin: 20px 0;">
    <h3 style="color: #333; margin-bottom: 20px; text-align: center;">ğŸ” ìŠ¤ë§ˆíŠ¸ ì§ˆë¬¸ ì¬êµ¬ì„±</h3>
    <p style="text-align: center; font-size: 16px; color: #555; margin-bottom: 25px;">
        ê°„ë‹¨í•œ ì§ˆë¬¸ë„ ìë™ìœ¼ë¡œ ë” ì •í™•í•˜ê²Œ ë³€í™˜ë©ë‹ˆë‹¤!
    </p>
    <div style="display: flex; justify-content: space-around; flex-wrap: wrap; gap: 20px;">
        <div style="background: rgba(255,255,255,0.3); padding: 20px; border-radius: 10px; text-align: center; min-width: 250px;">
            <h5 style="color: #333; margin-bottom: 10px;">ê°„ë‹¨í•œ ì§ˆë¬¸</h5>
            <p style="color: #555; font-size: 14px;">"ê´œì°®ì•„?"</p>
            <p style="color: #333; font-weight: bold;">â†“</p>
            <p style="color: #555; font-size: 14px;">"ì´ ê³„ì•½ì˜ ì£¼ìš” ì¡°ê±´ê³¼ ìœ„í—˜ ìš”ì†ŒëŠ”?"</p>
        </div>
        <div style="background: rgba(255,255,255,0.3); padding: 20px; border-radius: 10px; text-align: center; min-width: 250px;">
            <h5 style="color: #333; margin-bottom: 10px;">ê°€ê²© ê´€ë ¨</h5>
            <p style="color: #555; font-size: 14px;">"ë¹„ì‹¸?"</p>
            <p style="color: #333; font-weight: bold;">â†“</p>
            <p style="color: #555; font-size: 14px;">"ì´ ê³„ì•½ì˜ ê°€ê²©ì´ ì‹œì¥ ëŒ€ë¹„ ì ì •í•œê°€ìš”?"</p>
        </div>
        <div style="background: rgba(255,255,255,0.3); padding: 20px; border-radius: 10px; text-align: center; min-width: 250px;">
            <h5 style="color: #333; margin-bottom: 10px;">ì¡°ê±´ ê´€ë ¨</h5>
            <p style="color: #555; font-size: 14px;">"ì¡°ê±´?"</p>
            <p style="color: #333; font-weight: bold;">â†“</p>
            <p style="color: #555; font-size: 14px;">"ì´ ê³„ì•½ì˜ ì£¼ìš” ì¡°ê±´ë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”"</p>
        </div>
    </div>
</div>
""", unsafe_allow_html=True)

# file upload in sidebar
with st.sidebar:
    st.header("ğŸ“„ ê³„ì•½ì„œ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader('ë¶€ë™ì‚° ê³„ì•½ì„œ PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”', type=['pdf'])
    
    # file upload logic
    if uploaded_file:
        vectorstore, raw_text = process_uploaded_file(uploaded_file)
        if vectorstore:
            st.session_state['vectorstore'] = vectorstore
            st.session_state['raw_text'] = raw_text
            st.session_state['upload_time'] = str(uploaded_file.uploaded_at) if hasattr(uploaded_file, 'uploaded_at') else str(hash(raw_text))
            st.session_state['file_name'] = uploaded_file.name
            st.success("âœ… ê³„ì•½ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ìºì‹œ í†µê³„ í‘œì‹œ
    st.header("ğŸ“Š ìºì‹œ í†µê³„")
    if 'qa_cache' in st.session_state:
        stats = st.session_state.qa_cache.get_stats()
        col1, col2 = st.columns(2)
        with col1:
            st.metric("íˆíŠ¸", stats['hits'])
            st.metric("ìºì‹œ í¬ê¸°", stats['cache_size'])
        with col2:
            st.metric("ë¯¸ìŠ¤", stats['misses'])
            st.metric("íˆíŠ¸ìœ¨", f"{stats['hit_rate']}%")
        
        if st.button("ğŸ—‘ï¸ ìºì‹œ ì´ˆê¸°í™”"):
            st.session_state.qa_cache.clear_all()
            st.success("ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
    
    # Re-ranking ì •ë³´ í‘œì‹œ
    st.markdown("""
    <div style="background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%); 
                border-radius: 10px; 
                padding: 15px; 
                margin: 10px 0;">
        <h4 style="color: #333; margin-bottom: 10px;">ğŸ”„ ìŠ¤ë§ˆíŠ¸ ì¬ì •ë ¬</h4>
        <p style="font-size: 13px; color: #555; margin-bottom: 8px;">
            ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë” ì •í™•í•˜ê²Œ ì¬ì •ë ¬í•©ë‹ˆë‹¤!
        </p>
        <div style="font-size: 12px; color: #666;">
            <strong>ì¬ì •ë ¬ ê¸°ì¤€:</strong><br>
            â€¢ í‚¤ì›Œë“œ ë§¤ì¹­ (40%)<br>
            â€¢ í…ìŠ¤íŠ¸ ê¸¸ì´ (20%)<br>
            â€¢ ìœ„ì¹˜ ì¤‘ìš”ë„ (20%)<br>
            â€¢ ì›ë³¸ ìˆœìœ„ (20%)
        </div>
    </div>
    """, unsafe_allow_html=True)
        
# chatbot greatings
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        ChatMessage(
            role="assistant", content="ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ë¶€ë™ì‚° ê³„ì•½ì„œë¥¼ ë¶„ì„í•´ë“œë¦¬ëŠ” ì „ë¬¸ ì±—ë´‡ì…ë‹ˆë‹¤. ğŸ“‹\n\nê³„ì•½ì„œë¥¼ ì—…ë¡œë“œí•˜ì‹œë©´ ë‹¤ìŒê³¼ ê°™ì€ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\nâ€¢ ê³„ì•½ì„œ ìš”ì•½ ë° ì£¼ìš” ë‚´ìš© ë¶„ì„\nâ€¢ ê³„ì•½ ì¡°ê±´ ê²€í†  ë° ìœ„í—˜ ìš”ì†Œ íŒŒì•…\nâ€¢ ë²•ì  ê²€í†  ì‚¬í•­ ì•ˆë‚´\nâ€¢ ê³„ì•½ì„œ ê´€ë ¨ ì§ˆì˜ì‘ë‹µ\n\n'ìš”ì•½'ì´ë¼ê³  ì…ë ¥í•˜ì‹œë©´ ê³„ì•½ì„œì˜ ì „ì²´ì ì¸ ë‚´ìš©ì„ ë¶„ì„í•´ë“œë¦¬ê³ , ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•˜ì‹œë©´ ê³„ì•½ì„œì—ì„œ ë‹µì„ ì°¾ì•„ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ğŸ "
        )
    ]

# conversation history print 
for msg in st.session_state.messages:
    st.chat_message(msg.role).write(msg.content)
    
# message interaction
if prompt := st.chat_input("'ìš”ì•½' ë˜ëŠ” ê³„ì•½ì„œ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!"):
    st.session_state.messages.append(ChatMessage(role="user", content=prompt))
    st.chat_message("user").write(prompt)

    with st.chat_message("assistant"):
        stream_handler = StreamHandler(st.empty())
        
        # vectorstoreì™€ raw_textê°€ ìˆëŠ”ì§€ í™•ì¸
        if 'vectorstore' not in st.session_state or 'raw_text' not in st.session_state:
            st.error("âš ï¸ ë¨¼ì € ê³„ì•½ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
            st.session_state["messages"].append(
                ChatMessage(role="assistant", content="ê³„ì•½ì„œë¥¼ ì—…ë¡œë“œí•œ í›„ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.")
            )
        else:
            if prompt == "ìš”ì•½":
                response = generate_summarize(st.session_state['raw_text'], stream_handler)
                st.session_state["messages"].append(
                    ChatMessage(role="assistant", content=response)
                )
            else:
                response = generate_response(prompt, st.session_state['vectorstore'], stream_handler)
                st.session_state["messages"].append(
                    ChatMessage(role="assistant", content=response)
                )